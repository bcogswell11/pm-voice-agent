import os
import json
import base64
import threading
import time
from flask import Flask, request, Response
from flask_sock import Sock
import websockets
import asyncio

# ----- Config -----
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_REALTIME_MODEL = os.getenv("OPENAI_REALTIME_MODEL", "gpt-4o-realtime-preview")
OPENAI_VOICE = os.getenv("OPENAI_VOICE", "alloy")  # pick any supported realtime voice
PUBLIC_BASE_URL = os.getenv("PUBLIC_BASE_URL", "")  # e.g., https://escallop-...herokuapp.com

app = Flask(__name__)
sock = Sock(app)

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/voice")
def voice():
    """
    Twilio will hit this on each inbound call.
    We respond with TwiML that tells Twilio to open a bidirectional Media Stream
    to our WebSocket endpoint at /stream.
    """
    # Convert https -> wss for the stream URL
    base = PUBLIC_BASE_URL.rstrip("/")
    if base.startswith("https://"):
        stream_url = "wss://" + base[len("https://"):] + "/stream"
    elif base.startswith("http://"):
        stream_url = "ws://" + base[len("http://"):] + "/stream"
    else:
        # Fallback: let Twilio attempt wss://YOUR-APP/stream if someone misconfigured PUBLIC_BASE_URL
        stream_url = base + "/stream"

    twiml = f"""<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Connect>
    <Stream url="{stream_url}"/>
  </Connect>
</Response>"""
    return Response(twiml, mimetype="text/xml")

# -------------------------------
# WebSocket: Twilio <-> Our Server <-> OpenAI Realtime
# -------------------------------

def _safe_get(d, *keys, default=None):
    cur = d
    for k in keys:
        if not isinstance(cur, dict) or k not in cur:
            return default
        cur = cur[k]
    return cur

async def openai_realtime_connect():
    """
    Opens a websocket connection to OpenAI Realtime API.
    Returns (ws, init_task) where ws is the connected websocket client.
    """
    # NOTE: If your account uses a different endpoint or version, adjust here.
    url = f"wss://api.openai.com/v1/realtime?model={OPENAI_REALTIME_MODEL}&voice={OPENAI_VOICE}"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "OpenAI-Beta": "realtime=v1",
    }
    ws = await websockets.connect(url, extra_headers=headers, ping_interval=20, ping_timeout=20, max_size=None)
    return ws

async def relay_twilio_to_openai(twilio_ws, openai_ws):
    """
    Read Twilio Media Stream messages and forward audio to OpenAI Realtime.
    Twilio sends JSON frames; audio chunks are base64 PCM μ-law 8kHz by default.
    """
    # Tell OpenAI to expect audio input (create input audio buffer)
    await openai_ws.send(json.dumps({"type": "input_audio_buffer.create"}))

    while True:
        try:
            msg = twilio_ws.receive()
            if msg is None:
                break
            data = json.loads(msg)

            event = data.get("event")
            if event == "start":
                # You can inspect stream metadata if needed
                pass
            elif event == "media":
                payload = _safe_get(data, "media", "payload", default=None)
                if payload:
                    audio_bytes = base64.b64decode(payload)
                    # Forward raw audio chunk to OpenAI buffer
                    await openai_ws.send(json.dumps({
                        "type": "input_audio_buffer.append",
                        "audio": base64.b64encode(audio_bytes).decode("utf-8")
                    }))
            elif event == "stop":
                # End of Twilio media
                break
        except Exception:
            break

    # Close the input buffer and ask for a response
    try:
        await openai_ws.send(json.dumps({"type": "input_audio_buffer.commit"}))
        await openai_ws.send(json.dumps({"type": "response.create", "response": {}}))
    except Exception:
        pass

async def relay_openai_to_twilio(twilio_ws, openai_ws):
    """
    Read audio generated by OpenAI and forward back to Twilio as 'media' frames.
    """
    # Twilio expects base64 μ-law 8kHz audio chunks in "media.payload"
    # OpenAI will stream audio via events like "response.output_audio.delta" (base64-encoded).
    try:
        async for raw in openai_ws:
            try:
                evt = json.loads(raw)
            except Exception:
                continue

            t = evt.get("type")
            if t in ("response.output_audio.delta", "response.audio.delta", "response.output_audio_chunk"):
                # Normalize: find the base64 audio content in evt
                # Different preview versions may nest fields slightly differently:
                b64audio = (
                    evt.get("audio") or
                    _safe_get(evt, "delta", "audio") or
                    _safe_get(evt, "data", "audio")
                )
                if b64audio:
                    # Send back to Twilio as a 'media' event
                    frame = {
                        "event": "media",
                        "media": {
                            "payload": b64audio  # already base64
                        }
                    }
                    try:
                        twilio_ws.send(json.dumps(frame))
                    except Exception:
                        break

            elif t in ("response.completed", "response.stop"):
                # End of response — let’s signal Twilio we’re done
                try:
                    twilio_ws.send(json.dumps({"event": "mark", "mark": {"name": "openai_done"}}))
                except Exception:
                    pass
                # Optionally, request the next turn or close
                # For basic MVP, we end after one response.
                break

    except Exception:
        pass

    # Finalize: tell Twilio the stream is over
    try:
        twilio_ws.send(json.dumps({"event": "stop"}))
    except Exception:
        pass

@sock.route("/stream")
def stream(ws):
    """
    Twilio connects here via WebSocket (wss).
    We open a parallel WebSocket to OpenAI and shuttle audio both ways.
    """
    if not OPENAI_API_KEY:
        # If no key, immediately end so Twilio doesn't hang
        try:
            ws.send(json.dumps({"event": "stop"}))
        except Exception:
            pass
        return

    # Each connection uses its own asyncio loop in a thread
    loop = asyncio.new_event_loop()

    def runner():
        asyncio.set_event_loop(loop)
        openai_ws = loop.run_until_complete(openai_realtime_connect())

        # Kick off two tasks: Twilio->OpenAI and OpenAI->Twilio
        sender = loop.create_task(relay_twilio_to_openai(ws, openai_ws))
        receiver = loop.create_task(relay_openai_to_twilio(ws, openai_ws))

        # Run both until complete
        gathered = asyncio.gather(sender, receiver, return_exceptions=True)
        loop.run_until_complete(gathered)

        # Clean up
        try:
            loop.run_until_complete(openai_ws.close())
        except Exception:
            pass

    thread = threading.Thread(target=runner, daemon=True)
    thread.start()

    # Keep this handler open while the thread runs; close when client closes
    try:
        while thread.is_alive():
            time.sleep(0.05)
    except Exception:
        pass

if __name__ == "__main__":
    # Local run (not used on Heroku). Heroku uses the Procfile.
    app.run(host="0.0.0.0", port=8000)
